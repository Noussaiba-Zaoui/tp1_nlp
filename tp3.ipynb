{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":131084,"sourceType":"datasetVersion","datasetId":2052}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#part 1 :preprocessing\nimport pandas as pd\n\n# Loading the dataset\ndf = pd.read_csv('/kaggle/input/movie-review/movie_review.csv')\n\n\ndf","metadata":{"execution":{"iopub.status.busy":"2024-03-19T22:41:23.615325Z","iopub.execute_input":"2024-03-19T22:41:23.616142Z","iopub.status.idle":"2024-03-19T22:41:23.828369Z","shell.execute_reply.started":"2024-03-19T22:41:23.616106Z","shell.execute_reply":"2024-03-19T22:41:23.827202Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"       fold_id cv_tag  html_id  sent_id  \\\n0            0  cv000    29590        0   \n1            0  cv000    29590        1   \n2            0  cv000    29590        2   \n3            0  cv000    29590        3   \n4            0  cv000    29590        4   \n...        ...    ...      ...      ...   \n64715        9  cv999    14636       20   \n64716        9  cv999    14636       21   \n64717        9  cv999    14636       22   \n64718        9  cv999    14636       23   \n64719        9  cv999    14636       24   \n\n                                                    text  tag  \n0      films adapted from comic books have had plenty...  pos  \n1      for starters , it was created by alan moore ( ...  pos  \n2      to say moore and campbell thoroughly researche...  pos  \n3      the book ( or \" graphic novel , \" if you will ...  pos  \n4      in other words , don't dismiss this film becau...  pos  \n...                                                  ...  ...  \n64715  that lack of inspiration can be traced back to...  neg  \n64716  like too many of the skits on the current inca...  neg  \n64717  after watching one of the \" roxbury \" skits on...  neg  \n64718   bump unsuspecting women , and . . . that's all .  neg  \n64719  after watching _a_night_at_the_roxbury_ , you'...  neg  \n\n[64720 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fold_id</th>\n      <th>cv_tag</th>\n      <th>html_id</th>\n      <th>sent_id</th>\n      <th>text</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>cv000</td>\n      <td>29590</td>\n      <td>0</td>\n      <td>films adapted from comic books have had plenty...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>cv000</td>\n      <td>29590</td>\n      <td>1</td>\n      <td>for starters , it was created by alan moore ( ...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>cv000</td>\n      <td>29590</td>\n      <td>2</td>\n      <td>to say moore and campbell thoroughly researche...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>cv000</td>\n      <td>29590</td>\n      <td>3</td>\n      <td>the book ( or \" graphic novel , \" if you will ...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>cv000</td>\n      <td>29590</td>\n      <td>4</td>\n      <td>in other words , don't dismiss this film becau...</td>\n      <td>pos</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>64715</th>\n      <td>9</td>\n      <td>cv999</td>\n      <td>14636</td>\n      <td>20</td>\n      <td>that lack of inspiration can be traced back to...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>64716</th>\n      <td>9</td>\n      <td>cv999</td>\n      <td>14636</td>\n      <td>21</td>\n      <td>like too many of the skits on the current inca...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>64717</th>\n      <td>9</td>\n      <td>cv999</td>\n      <td>14636</td>\n      <td>22</td>\n      <td>after watching one of the \" roxbury \" skits on...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>64718</th>\n      <td>9</td>\n      <td>cv999</td>\n      <td>14636</td>\n      <td>23</td>\n      <td>bump unsuspecting women , and . . . that's all .</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>64719</th>\n      <td>9</td>\n      <td>cv999</td>\n      <td>14636</td>\n      <td>24</td>\n      <td>after watching _a_night_at_the_roxbury_ , you'...</td>\n      <td>neg</td>\n    </tr>\n  </tbody>\n</table>\n<p>64720 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Cleaning\nimport re\n\n# Clean the 'text' column: removing punctuation and underscores\ndf[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r'[^\\w\\s]|_', '', str(x)))\n\n\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T22:42:27.550200Z","iopub.execute_input":"2024-03-19T22:42:27.550636Z","iopub.status.idle":"2024-03-19T22:42:28.222655Z","shell.execute_reply.started":"2024-03-19T22:42:27.550604Z","shell.execute_reply":"2024-03-19T22:42:28.221382Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"       fold_id cv_tag  html_id  sent_id  \\\n0            0  cv000    29590        0   \n1            0  cv000    29590        1   \n2            0  cv000    29590        2   \n3            0  cv000    29590        3   \n4            0  cv000    29590        4   \n...        ...    ...      ...      ...   \n64715        9  cv999    14636       20   \n64716        9  cv999    14636       21   \n64717        9  cv999    14636       22   \n64718        9  cv999    14636       23   \n64719        9  cv999    14636       24   \n\n                                                    text  tag  \n0      films adapted from comic books have had plenty...  pos  \n1      for starters  it was created by alan moore  an...  pos  \n2      to say moore and campbell thoroughly researche...  pos  \n3      the book  or  graphic novel   if you will  is ...  pos  \n4      in other words  dont dismiss this film because...  pos  \n...                                                  ...  ...  \n64715  that lack of inspiration can be traced back to...  neg  \n64716  like too many of the skits on the current inca...  neg  \n64717  after watching one of the  roxbury  skits on s...  neg  \n64718         bump unsuspecting women  and    thats all   neg  \n64719  after watching anightattheroxbury  youll be le...  neg  \n\n[64720 rows x 6 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Normalize the text  column:\n\ndf[\"text\"] = df[\"text\"].str.lower()\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T22:42:49.555775Z","iopub.execute_input":"2024-03-19T22:42:49.556345Z","iopub.status.idle":"2024-03-19T22:42:49.619809Z","shell.execute_reply.started":"2024-03-19T22:42:49.556302Z","shell.execute_reply":"2024-03-19T22:42:49.618582Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"       fold_id cv_tag  html_id  sent_id  \\\n0            0  cv000    29590        0   \n1            0  cv000    29590        1   \n2            0  cv000    29590        2   \n3            0  cv000    29590        3   \n4            0  cv000    29590        4   \n...        ...    ...      ...      ...   \n64715        9  cv999    14636       20   \n64716        9  cv999    14636       21   \n64717        9  cv999    14636       22   \n64718        9  cv999    14636       23   \n64719        9  cv999    14636       24   \n\n                                                    text  tag  \n0      films adapted from comic books have had plenty...  pos  \n1      for starters  it was created by alan moore  an...  pos  \n2      to say moore and campbell thoroughly researche...  pos  \n3      the book  or  graphic novel   if you will  is ...  pos  \n4      in other words  dont dismiss this film because...  pos  \n...                                                  ...  ...  \n64715  that lack of inspiration can be traced back to...  neg  \n64716  like too many of the skits on the current inca...  neg  \n64717  after watching one of the  roxbury  skits on s...  neg  \n64718         bump unsuspecting women  and    thats all   neg  \n64719  after watching anightattheroxbury  youll be le...  neg  \n\n[64720 rows x 6 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('wordnet')\n\n# Tokenization: splitting the string into a list of words\nfrom nltk.tokenize import word_tokenize\nfrom nltk import sent_tokenize\n#used a lambda expression :\ndf['text'] = df['text'].apply(lambda x: word_tokenize(str(x)))\n\nprint(df['text'])","metadata":{"execution":{"iopub.status.busy":"2024-03-19T22:43:59.183696Z","iopub.execute_input":"2024-03-19T22:43:59.184119Z","iopub.status.idle":"2024-03-19T22:44:57.087469Z","shell.execute_reply.started":"2024-03-19T22:43:59.184087Z","shell.execute_reply":"2024-03-19T22:44:57.086003Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n0        [films, adapted, from, comic, books, have, had...\n1        [for, starters, it, was, created, by, alan, mo...\n2        [to, say, moore, and, campbell, thoroughly, re...\n3        [the, book, or, graphic, novel, if, you, will,...\n4        [in, other, words, dont, dismiss, this, film, ...\n                               ...                        \n64715    [that, lack, of, inspiration, can, be, traced,...\n64716    [like, too, many, of, the, skits, on, the, cur...\n64717    [after, watching, one, of, the, roxbury, skits...\n64718         [bump, unsuspecting, women, and, thats, all]\n64719    [after, watching, anightattheroxbury, youll, b...\nName: text, Length: 64720, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"#Removing stop_words : Removing not meaningful words.\nfrom nltk.corpus import stopwords\n\nnltk.download('stopwords')\n\n# Get the English stop words\n\nstop_words = stopwords.words('english')\n\n\ndf['text'] = df['text'].apply(lambda sentence_tokens: [word for word in sentence_tokens if word not in stop_words ])\n\nprint(df['text'])","metadata":{"execution":{"iopub.status.busy":"2024-03-19T22:45:39.372951Z","iopub.execute_input":"2024-03-19T22:45:39.373331Z","iopub.status.idle":"2024-03-19T22:46:02.136438Z","shell.execute_reply.started":"2024-03-19T22:45:39.373304Z","shell.execute_reply":"2024-03-19T22:46:02.135259Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n0        [films, adapted, comic, books, plenty, success...\n1        [starters, created, alan, moore, eddie, campbe...\n2        [say, moore, campbell, thoroughly, researched,...\n3        [book, graphic, novel, 500, pages, long, inclu...\n4                     [words, dont, dismiss, film, source]\n                               ...                        \n64715    [lack, inspiration, traced, back, insipid, cha...\n64716    [like, many, skits, current, incarnation, satu...\n64717    [watching, one, roxbury, skits, snl, come, awa...\n64718                   [bump, unsuspecting, women, thats]\n64719    [watching, anightattheroxbury, youll, left, ex...\nName: text, Length: 64720, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"#word2vec :\nimport gensim\n#affecting to each word of my dataSet a vector (size=100)\n\n# training my Word2Vec model\nmodel =gensim.models.Word2Vec(sentences=df['text'], vector_size=100, window=5, min_count=1, workers=8)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T23:09:08.003780Z","iopub.execute_input":"2024-03-19T23:09:08.004239Z","iopub.status.idle":"2024-03-19T23:09:14.507721Z","shell.execute_reply.started":"2024-03-19T23:09:08.004207Z","shell.execute_reply":"2024-03-19T23:09:14.506777Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#we can use the model to calculate the similariy between two words\nmodel.wv.similarity(w1=\"films\", w2=\"comic\")","metadata":{"execution":{"iopub.status.busy":"2024-03-19T23:12:22.170187Z","iopub.execute_input":"2024-03-19T23:12:22.170712Z","iopub.status.idle":"2024-03-19T23:12:22.179805Z","shell.execute_reply.started":"2024-03-19T23:12:22.170676Z","shell.execute_reply":"2024-03-19T23:12:22.178600Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0.709806"},"metadata":{}}]},{"cell_type":"code","source":"# for example the vector representing the word films is : \nword_vector = model.wv['films']\nword_vector ","metadata":{"execution":{"iopub.status.busy":"2024-03-19T23:10:16.269670Z","iopub.execute_input":"2024-03-19T23:10:16.270431Z","iopub.status.idle":"2024-03-19T23:10:16.278829Z","shell.execute_reply.started":"2024-03-19T23:10:16.270393Z","shell.execute_reply":"2024-03-19T23:10:16.277787Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([-6.59076035e-01,  1.19481528e+00,  6.67670965e-01,  8.76661956e-01,\n        1.47170734e+00, -7.90645182e-01,  1.43346381e+00,  1.94002759e+00,\n       -6.87446177e-01,  4.28435877e-02, -1.04348734e-01, -1.92373025e+00,\n        7.52190471e-01,  4.07082736e-01,  4.34483200e-01, -5.68841696e-01,\n        6.39031172e-01,  1.68243289e-01, -6.34219885e-01, -2.10728884e+00,\n        7.33670294e-01,  2.51250684e-01,  7.61865854e-01, -1.77564991e+00,\n        1.20582774e-01, -5.99515378e-01, -1.13715804e+00, -4.02291983e-01,\n       -1.27393126e+00,  3.73971090e-02,  1.31265700e-01, -2.06803232e-01,\n        1.07967782e+00,  1.49195374e-03, -1.19922245e+00,  1.38112044e+00,\n        5.25577068e-01,  1.00421570e-01,  9.64614600e-02, -1.37798333e+00,\n       -8.83434936e-02, -4.82830495e-01,  1.49303436e-01,  4.42844927e-01,\n        8.43595624e-01,  3.70592654e-01, -1.96873605e-01,  1.69483215e-01,\n       -2.11658068e-02,  7.57974386e-01,  5.47954559e-01,  3.22361946e-01,\n        4.73044008e-01, -3.03285778e-01,  1.02562206e-02,  9.31546241e-02,\n        1.34637547e+00, -2.60571241e-02, -5.15104830e-01,  2.81141222e-01,\n       -1.45717159e-01, -6.17415905e-01, -3.45067382e-02, -8.47194552e-01,\n       -2.09463811e+00,  1.57647952e-01, -6.76014796e-02,  1.54455245e-01,\n       -1.56252170e+00,  1.23336399e+00, -1.49099314e+00, -3.12095821e-01,\n        9.85811353e-01, -1.01084375e+00,  4.47707862e-01, -8.08557689e-01,\n       -1.58043229e-04, -2.75744498e-02, -1.12911928e+00,  1.16307509e+00,\n       -5.52454352e-01, -5.53788364e-01,  2.45416209e-01,  7.82794297e-01,\n       -3.10934275e-01, -3.82430077e-01, -1.66780204e-01,  1.34535205e+00,\n        9.75088596e-01,  1.47361350e+00,  3.91316801e-01, -5.91612279e-01,\n        1.04296410e+00, -3.00043255e-01,  2.00412917e+00,  1.05289280e+00,\n        3.27971607e-01,  3.36624205e-01,  1.28764427e+00,  8.35743248e-02],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n# pour chaque mot du vocabulaire , on va récuperer le vecteur correspondants et on va  stocké l'ensemble de ces vecteurs dans un tab\ndef get_word_embeddings(review, model):\n    word_embeddings = []\n    for word in review:\n        #Vérifier Si le mot est présent dans le vocabulaire du modèle :c'est-à-dire qu'il a été vu lors de l'entraînement du modèle\n        if word in model.wv.key_to_index:\n            word_embeddings.append(model.wv[word])\n    return word_embeddings\n\n# Fonction pour obtenir le vecteur moyen d'une critique\ndef get_review_vector(review, model):\n    word_embeddings = get_word_embeddings(review, model)\n    if word_embeddings:\n        return np.mean(word_embeddings, axis=0)\n    else:\n        # Si la critique ne contient pas de mots dans le vocabulaire du modèle, retourner un vecteur nul\n        return np.zeros(model.vector_size)\n\n\ndf['review_vector'] = df['text'].apply(lambda x: get_review_vector(x, model))\ndf['review_vector']","metadata":{"execution":{"iopub.status.busy":"2024-03-19T23:20:54.555119Z","iopub.execute_input":"2024-03-19T23:20:54.556203Z","iopub.status.idle":"2024-03-19T23:20:58.645783Z","shell.execute_reply.started":"2024-03-19T23:20:54.556169Z","shell.execute_reply":"2024-03-19T23:20:58.644542Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0        [-0.29437578, 0.6844872, 0.27564168, 0.0929046...\n1        [-0.16242625, 0.39859912, 0.23955342, 0.134385...\n2        [-0.30801386, 0.7278831, 0.26668298, 0.0373448...\n3        [-0.17460036, 0.4626064, 0.25689456, 0.1374812...\n4        [-0.3734592, 0.79059666, 0.2860926, 0.14194557...\n                               ...                        \n64715    [-0.118355155, 0.6174714, 0.26097655, 0.001273...\n64716    [-0.21660297, 0.60104614, 0.22306864, 0.031008...\n64717    [-0.32119262, 0.7532886, 0.3251984, 0.13015431...\n64718    [-0.24686356, 0.6078703, 0.24496786, 0.0766055...\n64719    [-0.47334653, 0.7256668, 0.2553075, 0.23306403...\nName: review_vector, Length: 64720, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\n\n# Convertir les listes de vecteurs en matrices NumPy : pour que les features et tragets aient des formes compatibles\nX_train = np.vstack(X_train)\nX_test = np.vstack(X_test)\n\n# Diviser les données : partie training te testing\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n\n# Créer et entraîner le modèle de régression logistique\nmodel1 = linear_model.LogisticRegression()\nmodel1.fit(X_train, y_train)\n\n# Évaluer le modèle sur l'ensemble de test\naccuracy = model1.score(X_test, y_test)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T23:38:37.082498Z","iopub.execute_input":"2024-03-19T23:38:37.083368Z","iopub.status.idle":"2024-03-19T23:38:38.629550Z","shell.execute_reply.started":"2024-03-19T23:38:37.083328Z","shell.execute_reply":"2024-03-19T23:38:38.628369Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Accuracy: 0.5585168018539977\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}]},{"cell_type":"code","source":"#prediction :(sachant que le .score l'effectue implicitement)\ny_pred = model1.predict(X_test)\n\n\nprint(\"Prédictions :\", y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T23:40:25.403313Z","iopub.execute_input":"2024-03-19T23:40:25.404586Z","iopub.status.idle":"2024-03-19T23:40:25.414731Z","shell.execute_reply.started":"2024-03-19T23:40:25.404542Z","shell.execute_reply":"2024-03-19T23:40:25.412939Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Prédictions : ['pos' 'neg' 'neg' ... 'pos' 'neg' 'neg']\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Calculer les prédictions sur l'ensemble de test\ny_pred = model1.predict(X_test)\n\n# Calculer les métriques d'évaluation\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted')\nrecall = recall_score(y_test, y_pred, average='weighted')\nf1 = f1_score(y_test, y_pred, average='weighted')\n\n# Afficher les résultats\nprint(\"Accuracy :\", accuracy)\nprint(\"Precision :\", precision)\nprint(\"Recall :\", recall)\nprint(\"F1-score :\", f1)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T23:41:46.834301Z","iopub.execute_input":"2024-03-19T23:41:46.834823Z","iopub.status.idle":"2024-03-19T23:41:47.416897Z","shell.execute_reply.started":"2024-03-19T23:41:46.834789Z","shell.execute_reply":"2024-03-19T23:41:47.415439Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Accuracy : 0.5585168018539977\nPrecision : 0.5592600732320318\nRecall : 0.5585168018539977\nF1-score : 0.5530040369605221\n","output_type":"stream"}]}]}